{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import joblib\n",
    "import xgboost\n",
    "from onnxmltools.convert import convert_xgboost\n",
    "\n",
    "from skl2onnx.common.data_types import FloatTensorType, DoubleTensorType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, name, ncols, TARGET_OPSET):\n",
    "        self.name = name\n",
    "        self.ncols = ncols\n",
    "        self.TARGET_OPSET = TARGET_OPSET\n",
    "\n",
    "datasets = [\n",
    "    DataSet(\"Acute_Inflammations\", 6, 15),\n",
    "    DataSet(\"Breast_Cancer\", 9, 15),\n",
    "    DataSet(\"Chronic_Kidney_Disease\", 24, 15),\n",
    "    DataSet(\"Heart_Disease\", 13, 15),\n",
    "    DataSet(\"Heart_Failure_Clinical_Records\", 12, 15),\n",
    "    DataSet(\"Lymphography\", 18, 15),\n",
    "    DataSet(\"Parkinsons\", 22, 15),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangzc/miniconda3/envs/giza/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [14:42:14] WARNING: /workspace/src/common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # load the xgboost model\n",
    "    model_path = f\"{dataset.name}/{dataset.name}.pkl\"\n",
    "    xgboost_clf = joblib.load(model_path)\n",
    "    onnx_model_converted = convert_xgboost(xgboost_clf, 'tree-based classifier',\n",
    "                             [('input', FloatTensorType([1, dataset.ncols]))],\n",
    "                             target_opset=dataset.TARGET_OPSET)\n",
    "    onnx.save_model(onnx_model_converted, f\"{dataset.name}/{dataset.name}.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acute_Inflammations/new_data.tsv\n",
      "predict [3]\n",
      "predict_proba [[0.02602444 0.02666548 0.04841037 0.89889973]]\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # load the xgboost model\n",
    "    if dataset.name == \"Acute_Inflammations\":\n",
    "        # load ONNX model\n",
    "        model_path = f\"{dataset.name}/{dataset.name}.onnx\"\n",
    "        # load data set\n",
    "        new_path = f\"{dataset.name}/new_data.tsv\"\n",
    "        print(new_path)\n",
    "        titanic = pd.read_table(new_path, sep=\"\\t\", header=None)\n",
    "        num_columns = titanic.shape[1]\n",
    "        # x = titanic[[i for i in range(num_columns-1)]]\n",
    "        # x = numpy.array(x)\n",
    "        # print(x[:5])\n",
    "        # y = titanic.iloc[:, -1]\n",
    "        # 0.9333333333333336  1.0 1.0 1.0 1.0 0.0 3.0\n",
    "        x = numpy.array([[0.06666666666666666643, 0.0, 0.0, 1.0, 1.0, 1.0], [0.9333333333333336, 1.0, 1.0, 1.0, 1.0, 0.0], [0.9333333333333336, 1.0, 1.0, 1.0, 1.0, 1.0], [0.9833333333333334, 0.0, 1.0, 1.0, 0.0, 1.0]])\n",
    "        sess = rt.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "        pred_onx = sess.run(None, {\"input\": x[1:2].astype(numpy.float32)})\n",
    "        print(\"predict\", pred_onx[0])\n",
    "        print(\"predict_proba\", pred_onx[1][:1])\n",
    "        # print(\"predict\", pred_onx[0].ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- inputs info -----------------\n",
      "{'name': 'input', 'shape': [1, 6], 'type': 'tensor(float)'}\n",
      "----------------- outputs info -----------------\n",
      "{'name': 'label', 'shape': [1], 'type': 'tensor(int64)'}\n",
      "{'name': 'probabilities', 'shape': [1, 4], 'type': 'tensor(float)'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import onnxruntime\n",
    "\n",
    "onnx_path = \"Acute_Inflammations/Acute_Inflammations.onnx\"\n",
    "# onnx_path = \"../decision_tree/decision_tree_ac.onnx\"\n",
    "\n",
    "provider = \"CPUExecutionProvider\"\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_path, providers=[provider])\n",
    "\n",
    "print(\"----------------- inputs info -----------------\")\n",
    "input_tensors = onnx_session.get_inputs()  \n",
    "for input_tensor in input_tensors:         \n",
    "    \n",
    "    input_info = {\n",
    "        \"name\" : input_tensor.name,\n",
    "        \"type\" : input_tensor.type,\n",
    "        \"shape\": input_tensor.shape,\n",
    "    }\n",
    "    pprint(input_info)\n",
    "\n",
    "print(\"----------------- outputs info -----------------\")\n",
    "output_tensors = onnx_session.get_outputs()  \n",
    "for output_tensor in output_tensors:         \n",
    "    \n",
    "    output_info = {\n",
    "        \"name\" : output_tensor.name,\n",
    "        \"type\" : output_tensor.type,\n",
    "        \"shape\": output_tensor.shape,\n",
    "    }\n",
    "    pprint(output_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
